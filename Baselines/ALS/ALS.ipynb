{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Set your data directory path\n",
    "DATA_DIR = '../../Data/'\n",
    "ratings_path = os.path.join(DATA_DIR, 'train_ratings.csv')\n",
    "wishlist_path = os.path.join(DATA_DIR, 'train_tbr.csv')\n",
    "sample_path = os.path.join(DATA_DIR, 'sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternating Least Squares (ALS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions + Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path):\n",
    "    \"\"\"\n",
    "    Load ratings CSV, split sid_pid into sid and pid, drop original column.\n",
    "    \"\"\"\n",
    "    ratings = pd.read_csv(train_path)\n",
    "    ratings[[\"sid\", \"pid\"]] = ratings[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    ratings.drop(columns=[\"sid_pid\"], inplace=True)\n",
    "    ratings[\"sid\"] = ratings[\"sid\"].astype(int)\n",
    "    ratings[\"pid\"] = ratings[\"pid\"].astype(int)\n",
    "    return ratings\n",
    "\n",
    "def read_data_matrix(df):\n",
    "    \"\"\"Returns matrix view of the training data, where rows are scientists (sid) and\n",
    "    columns are papers (pid).\"\"\"\n",
    "    return df.pivot(index=\"sid\", columns=\"pid\", values=\"rating\").fillna(0)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def make_submission(model, filename):\n",
    "    \"\"\"\n",
    "    Generate submission file\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: trained ALS model\n",
    "    filename: path to save submission file\n",
    "    \"\"\"\n",
    "    # Load sample submission file\n",
    "    df = pd.read_csv(sample_path)\n",
    "    \n",
    "    # Extract sids and pids\n",
    "    sid_pid = df[\"sid_pid\"].str.split(\"_\", expand=True)\n",
    "    sids = sid_pid[0].astype(int).values\n",
    "    pids = sid_pid[1].astype(int).values\n",
    "    \n",
    "    # Predict ratings\n",
    "    df[\"rating\"] = model.predict_for_submission(sids, pids)\n",
    "    \n",
    "    # Save submission file\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Submission saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1128187 ratings\n",
      "Training set: 902549, Test set: 225638\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "ratings = load_data(ratings_path)\n",
    "print(f\"Loaded {len(ratings)} ratings\")\n",
    "\n",
    "# Split data for training and testing\n",
    "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "print(f\"Training set: {len(train_data)}, Test set: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedALSModel:\n",
    "    def __init__(self, rank=100, num_iterations=10, reg_parameter=0.1, num_svd_runs=3, \n",
    "                 svd_lr=0.1, use_iSVD=False, transpose=False, bias_reg=0.01, \n",
    "                 use_bias=True, use_confidence=True, alpha=40):\n",
    "        \"\"\"\n",
    "        Initialize enhanced ALS model with hyperparameters\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        rank: int, default=100\n",
    "            Number of latent factors\n",
    "        num_iterations: int, default=10\n",
    "            Number of ALS iterations\n",
    "        reg_parameter: float, default=0.1\n",
    "            Regularization parameter\n",
    "        num_svd_runs: int, default=3\n",
    "            Number of SVD iterations for initialization\n",
    "        svd_lr: float, default=0.1\n",
    "            Learning rate for SVD\n",
    "        use_iSVD: bool, default=False\n",
    "            Whether to use iSVD or proj_SVD\n",
    "        transpose: bool, default=False\n",
    "            Whether to transpose the rating matrix\n",
    "        bias_reg: float, default=0.01\n",
    "            Regularization parameter for bias terms\n",
    "        use_bias: bool, default=True\n",
    "            Whether to use bias terms in the model\n",
    "        use_confidence: bool, default=True\n",
    "            Whether to use confidence weighting\n",
    "        alpha: float, default=40\n",
    "            Confidence scaling factor\n",
    "        \"\"\"\n",
    "        self.rank = rank\n",
    "        self.num_iters = num_iterations\n",
    "        self.lam = reg_parameter\n",
    "        self.num_svd_runs = num_svd_runs\n",
    "        self.lr = svd_lr\n",
    "        self.use_iSVD = use_iSVD\n",
    "        self.transpose = transpose\n",
    "        self.bias_reg = bias_reg\n",
    "        self.use_bias = use_bias\n",
    "        self.use_confidence = use_confidence\n",
    "        self.alpha = alpha\n",
    "        self.rec_mtx = None\n",
    "        \n",
    "    def extract_data(self, data):\n",
    "        \"\"\"Extract user and item indices and ratings\"\"\"\n",
    "        users = data[\"sid\"].values\n",
    "        items = data[\"pid\"].values\n",
    "        predictions = data[\"rating\"].values\n",
    "        return users, items, predictions\n",
    "    \n",
    "    def proj_SVD(self, A, mask, lr=0.1, rank=10, num_iters=10):\n",
    "        \"\"\"Projected SVD for initialization\"\"\"\n",
    "        U = np.random.uniform(low=-1.0, high=1.0, size=(A.shape[0], rank))\n",
    "        V = np.random.uniform(low=-1.0, high=1.0, size=(rank, A.shape[1]))\n",
    "        A_curr = np.zeros((A.shape[0], A.shape[1]))\n",
    "        for _ in range(num_iters):\n",
    "            diff = np.multiply(np.subtract(A, A_curr), mask)\n",
    "            pre_svd = A_curr + lr*diff\n",
    "            u, s, vt = svds(pre_svd, k=rank)\n",
    "            # Sort singular values in descending order\n",
    "            idx = np.argsort(s)[::-1]\n",
    "            s = s[idx]\n",
    "            u = u[:, idx]\n",
    "            vt = vt[idx, :]\n",
    "            \n",
    "            S = np.diag(s)\n",
    "            U = u.dot(np.sqrt(S))\n",
    "            V = np.sqrt(S).dot(vt)\n",
    "            A_curr = U.dot(V)\n",
    "        return U, V, A_curr\n",
    "    \n",
    "    def iSVD(self, A, mask, rank=10, num_iters=3):\n",
    "        \"\"\"Incremental SVD for initialization\"\"\"\n",
    "        U = np.random.uniform(low=-1.0, high=1.0, size=(A.shape[0], rank))\n",
    "        V = np.random.uniform(low=-1.0, high=1.0, size=(rank, A.shape[1]))\n",
    "        A_curr = A\n",
    "        for _ in range(num_iters):\n",
    "            u, s, vt = svds(A_curr, k=rank)\n",
    "            # Sort singular values in descending order\n",
    "            idx = np.argsort(s)[::-1]\n",
    "            s = s[idx]\n",
    "            u = u[:, idx]\n",
    "            vt = vt[idx, :]\n",
    "            \n",
    "            S = np.diag(s)\n",
    "            U = u.dot(np.sqrt(S))\n",
    "            V = np.sqrt(S).dot(vt)\n",
    "            A_curr = np.multiply(A, mask) + np.multiply(U@V, 1-mask)\n",
    "        return U, V, A_curr\n",
    "    \n",
    "    def calculate_confidence(self, ratings):\n",
    "        \"\"\"Calculate confidence weights based on ratings\"\"\"\n",
    "        # Higher ratings get higher confidence\n",
    "        return 1 + self.alpha * (ratings - 1) / 4\n",
    "    \n",
    "    def ALS(self, users, items, preds):\n",
    "        \"\"\"\n",
    "        Implement ALS algorithm with bias terms and confidence weighting\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        users: array of user indices\n",
    "        items: array of item indices\n",
    "        preds: array of ratings\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        rec_mtx: reconstructed rating matrix\n",
    "        \"\"\"\n",
    "        # Determine dimensions\n",
    "        max_user = max(users) + 1\n",
    "        max_movie = max(items) + 1\n",
    "        rows, cols = max_user, max_movie\n",
    "        \n",
    "        # Create data matrix and mask\n",
    "        data = np.zeros((rows, cols))\n",
    "        mask = np.zeros((rows, cols))\n",
    "        \n",
    "        # Fill data matrix with ratings\n",
    "        for user, item, pred in zip(users, items, preds):\n",
    "            data[user][item] = pred\n",
    "            mask[user][item] = 1\n",
    "        \n",
    "        # Create confidence matrix if using confidence weighting\n",
    "        if self.use_confidence:\n",
    "            confidence = np.zeros((rows, cols))\n",
    "            for user, item, pred in zip(users, items, preds):\n",
    "                confidence[user][item] = self.calculate_confidence(pred)\n",
    "        else:\n",
    "            confidence = mask.copy()\n",
    "            \n",
    "        # Normalize data\n",
    "        if self.transpose:\n",
    "            axis = 1\n",
    "        else:\n",
    "            axis = 0\n",
    "            \n",
    "        # Calculate global mean\n",
    "        global_mean = np.nanmean(np.where(data != 0, data, np.nan))\n",
    "        \n",
    "        # Calculate user and item bias terms\n",
    "        user_mean = np.nanmean(np.where(data != 0, data, np.nan), axis=1)\n",
    "        user_mean = np.nan_to_num(user_mean, nan=global_mean)\n",
    "        item_mean = np.nanmean(np.where(data != 0, data, np.nan), axis=0)\n",
    "        item_mean = np.nan_to_num(item_mean, nan=global_mean)\n",
    "        \n",
    "        # Calculate user and item bias\n",
    "        if self.use_bias:\n",
    "            user_bias = user_mean - global_mean\n",
    "            item_bias = item_mean - global_mean\n",
    "        else:\n",
    "            user_bias = np.zeros(rows)\n",
    "            item_bias = np.zeros(cols)\n",
    "        \n",
    "        # Adjust data for biases\n",
    "        A = data.copy()\n",
    "        if self.use_bias:\n",
    "            for i in range(rows):\n",
    "                for j in range(cols):\n",
    "                    if mask[i, j]:\n",
    "                        A[i, j] = data[i, j] - global_mean - user_bias[i] - item_bias[j]\n",
    "        \n",
    "        # SVD initialization\n",
    "        U, V = None, None\n",
    "        if self.use_iSVD:\n",
    "            U, V, _ = self.iSVD(A, mask, self.rank, self.num_svd_runs)\n",
    "        else:\n",
    "            U, V, _ = self.proj_SVD(A, mask, self.lr, self.rank, self.num_svd_runs)\n",
    "            \n",
    "        # ALS iterations\n",
    "        for _ in range(self.num_iters):\n",
    "            # Update item factors (V)\n",
    "            for j in range(cols):\n",
    "                # Get users who rated this item\n",
    "                users_idx = np.where(mask[:, j])[0]\n",
    "                if len(users_idx) > 0:\n",
    "                    U_j = U[users_idx, :]\n",
    "                    A_j = A[users_idx, j]\n",
    "                    C_j = confidence[users_idx, j]\n",
    "                    \n",
    "                    # Weighted regularization\n",
    "                    WU = (U_j.T * C_j) @ U_j\n",
    "                    reg = self.lam * np.eye(self.rank)\n",
    "                    V[:, j] = np.linalg.solve(WU + reg, (U_j.T * C_j) @ A_j)\n",
    "            \n",
    "            # Update user factors (U)\n",
    "            for i in range(rows):\n",
    "                # Get items rated by this user\n",
    "                items_idx = np.where(mask[i, :])[0]\n",
    "                if len(items_idx) > 0:\n",
    "                    V_i = V[:, items_idx]\n",
    "                    A_i = A[i, items_idx]\n",
    "                    C_i = confidence[i, items_idx]\n",
    "                    \n",
    "                    # Weighted regularization\n",
    "                    WV = V_i @ (np.diag(C_i) @ V_i.T)\n",
    "                    reg = self.lam * np.eye(self.rank)\n",
    "                    U[i, :] = np.linalg.solve(WV + reg, V_i @ (np.diag(C_i) @ A_i))\n",
    "            \n",
    "            # Update bias terms if using bias\n",
    "            if self.use_bias:\n",
    "                # Update user bias\n",
    "                for i in range(rows):\n",
    "                    items_idx = np.where(mask[i, :])[0]\n",
    "                    if len(items_idx) > 0:\n",
    "                        bias_residuals = data[i, items_idx] - global_mean - item_bias[items_idx] - U[i, :] @ V[:, items_idx]\n",
    "                        user_bias[i] = np.sum(bias_residuals) / (len(items_idx) + self.bias_reg)\n",
    "                \n",
    "                # Update item bias\n",
    "                for j in range(cols):\n",
    "                    users_idx = np.where(mask[:, j])[0]\n",
    "                    if len(users_idx) > 0:\n",
    "                        bias_residuals = data[users_idx, j] - global_mean - user_bias[users_idx] - np.sum(U[users_idx, :] * V[:, j], axis=1)\n",
    "                        item_bias[j] = np.sum(bias_residuals) / (len(users_idx) + self.bias_reg)\n",
    "                        \n",
    "        # Generate predictions\n",
    "        output = np.zeros((rows, cols))\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                output[i, j] = global_mean + user_bias[i] + item_bias[j] + U[i, :] @ V[:, j]\n",
    "                \n",
    "        # Clip predictions to valid rating range [1, 5]\n",
    "        rec_mtx = np.clip(output, 1, 5)\n",
    "        \n",
    "        # Store model parameters for prediction\n",
    "        self.user_factors = U\n",
    "        self.item_factors = V\n",
    "        self.global_mean = global_mean\n",
    "        self.user_bias = user_bias\n",
    "        self.item_bias = item_bias\n",
    "        \n",
    "        return rec_mtx\n",
    "    \n",
    "    def train(self, train_data, test_data=None):\n",
    "        \"\"\"\n",
    "        Train the ALS model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        train_data: DataFrame with columns ['sid','pid','rating']\n",
    "        test_data: DataFrame with columns ['sid','pid','rating'] or None\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        test_score: RMSE on test data (if test_data is provided)\n",
    "        \"\"\"\n",
    "        # Extract data\n",
    "        self.train_users, self.train_items, self.train_predictions = self.extract_data(train_data)\n",
    "        \n",
    "        if test_data is not None:\n",
    "            self.test_users, self.test_items, self.test_predictions = self.extract_data(test_data)\n",
    "        \n",
    "        # Train model\n",
    "        self.rec_mtx = self.ALS(self.train_users, self.train_items, self.train_predictions)\n",
    "        \n",
    "        # Evaluate on test data if provided\n",
    "        if test_data is not None:\n",
    "            preds = self.predict_ratings(test_data)\n",
    "            test_score = math.sqrt(mean_squared_error(self.test_predictions, preds))\n",
    "            return test_score\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def predict_ratings(self, test_data):\n",
    "        \"\"\"\n",
    "        Predict ratings for test data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_data: DataFrame with columns ['sid','pid','rating']\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        predictions: array of predicted ratings\n",
    "        \"\"\"\n",
    "        users, items, _ = self.extract_data(test_data)\n",
    "        predictions = np.zeros(len(users))\n",
    "        \n",
    "        for i, (user, item) in enumerate(zip(users, items)):\n",
    "            # Check if indices are in bounds\n",
    "            if user < self.rec_mtx.shape[0] and item < self.rec_mtx.shape[1]:\n",
    "                predictions[i] = self.rec_mtx[user][item]\n",
    "            else:\n",
    "                # For users or items not seen during training, predict using available information\n",
    "                if user < self.rec_mtx.shape[0] and hasattr(self, 'user_bias'):\n",
    "                    # We have user but not item\n",
    "                    predictions[i] = self.global_mean + self.user_bias[user]\n",
    "                elif item < self.rec_mtx.shape[1] and hasattr(self, 'item_bias'):\n",
    "                    # We have item but not user\n",
    "                    predictions[i] = self.global_mean + self.item_bias[item]\n",
    "                else:\n",
    "                    # Neither user nor item seen before\n",
    "                    predictions[i] = self.global_mean if hasattr(self, 'global_mean') else 3.0\n",
    "                \n",
    "        return predictions\n",
    "    \n",
    "    def predict_for_submission(self, sids, pids):\n",
    "        \"\"\"\n",
    "        Predict ratings for submission file\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        sids: array of user indices\n",
    "        pids: array of item indices\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        predictions: array of predicted ratings\n",
    "        \"\"\"\n",
    "        predictions = np.zeros(len(sids))\n",
    "        \n",
    "        for i, (sid, pid) in enumerate(zip(sids, pids)):\n",
    "            # Check if indices are in bounds\n",
    "            if sid < self.rec_mtx.shape[0] and pid < self.rec_mtx.shape[1]:\n",
    "                predictions[i] = self.rec_mtx[sid][pid]\n",
    "            else:\n",
    "                # For users or items not seen during training, use bias terms if available\n",
    "                if sid < self.rec_mtx.shape[0] and hasattr(self, 'user_bias'):\n",
    "                    # We have user but not item\n",
    "                    predictions[i] = self.global_mean + self.user_bias[sid]\n",
    "                elif pid < self.rec_mtx.shape[1] and hasattr(self, 'item_bias'):\n",
    "                    # We have item but not user\n",
    "                    predictions[i] = self.global_mean + self.item_bias[pid]\n",
    "                else:\n",
    "                    # Neither user nor item seen before\n",
    "                    predictions[i] = self.global_mean if hasattr(self, 'global_mean') else 3.0\n",
    "                \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(train_data, val_data, param_grid):\n",
    "    \"\"\"\n",
    "    Tune hyperparameters using grid search\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data: DataFrame with columns ['sid','pid','rating']\n",
    "    val_data: DataFrame with columns ['sid','pid','rating']\n",
    "    param_grid: dict of hyperparameter ranges\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    best_params: dict of best hyperparameters\n",
    "    best_model: best model\n",
    "    best_rmse: best RMSE score\n",
    "    \"\"\"\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Convert param_grid to list of dictionaries\n",
    "    from itertools import product\n",
    "    keys = param_grid.keys()\n",
    "    values = param_grid.values()\n",
    "    param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "    \n",
    "    print(f\"Evaluating {len(param_combinations)} hyperparameter combinations\")\n",
    "    \n",
    "    for params in param_combinations:\n",
    "        print(f\"Evaluating parameters: {params}\")\n",
    "        \n",
    "        model = EnhancedALSModel(\n",
    "            rank=params['factors'],\n",
    "            num_iterations=params['iterations'],\n",
    "            reg_parameter=params['regularization'],\n",
    "            num_svd_runs=params.get('num_svd_runs', 3),\n",
    "            svd_lr=params.get('svd_lr', 0.1),\n",
    "            use_iSVD=params.get('use_iSVD', False),\n",
    "            transpose=params.get('transpose', False)\n",
    "        )\n",
    "        \n",
    "        val_rmse = model.train(train_data, val_data)\n",
    "        print(f\"Validation RMSE: {val_rmse}\")\n",
    "        \n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse = val_rmse\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "            \n",
    "    return best_params, best_model, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'factors': [10,20,30,40 ], \n",
    "    'regularization': [0.1, 0.2, 0.35, 0.5, 0.6, 0.7, 0.754, 0.8], \n",
    "    'iterations': [1,2,5,10,20,50,100], \n",
    "    'num_svd_runs': [3,4,5,6,7],\n",
    "    'svd_lr': [4,5,5.5,6,6.5,6.6,6.65,6.7,6.75,6.9,7,7.1,7.2,7.5,8,9],\n",
    "    'use_iSVD': [False],\n",
    "    'transpose': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 1 hyperparameter combinations\n",
      "Evaluating parameters: {'factors': 40, 'regularization': 0.6, 'iterations': 1, 'num_svd_runs': 6, 'svd_lr': 5.5, 'use_iSVD': False, 'transpose': False}\n",
      "Validation RMSE: 0.8672560086578185\n",
      "Best parameters: {'factors': 40, 'regularization': 0.6, 'iterations': 1, 'num_svd_runs': 6, 'svd_lr': 5.5, 'use_iSVD': False, 'transpose': False}, Best RMSE: 0.8672560086578185\n"
     ]
    }
   ],
   "source": [
    "best_params, best_model, best_rmse = tune_hyperparameters(train_data, test_data, param_grid)\n",
    "print(f\"Best parameters: {best_params}, Best RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model with specific parameters\n",
    "model = EnhancedALSModel(\n",
    "    rank=40,\n",
    "    num_iterations=1,\n",
    "    reg_parameter=0.6,\n",
    "    num_svd_runs=6,\n",
    "    svd_lr=5.5,\n",
    "    use_iSVD=False,\n",
    "    transpose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8672560086578184\n",
      "âœ… Compressed model written to ../../saved_models/als_model.joblib\n",
      "ðŸ—„ï¸  Model file is 79.74 MB on disk\n"
     ]
    }
   ],
   "source": [
    "# Train the model and get validation RMSE\n",
    "val_rmse = model.train(train_data, test_data)\n",
    "print(f\"Validation RMSE: {val_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to /Users/ccylmichel/Documents/CIL/BayesWatch_CollaborativeFiltering/Data/sample_submissionALS.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate submission file\n",
    "make_submission(model, os.path.join(DATA_DIR, 'sample_submissionALS.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
